{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13934712,"sourceType":"datasetVersion","datasetId":8864409}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/vanha2301/voiceover-dubbing?scriptVersionId=282937186\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Voice","metadata":{}},{"cell_type":"markdown","source":"## C√†i ƒë·∫∑t th∆∞ vi·ªán v√† T·∫£i video m·∫´u","metadata":{}},{"cell_type":"code","source":"# 1. C√†i ƒë·∫∑t th∆∞ vi·ªán faster-whisper (phi√™n b·∫£n ch·∫°y nhanh tr√™n GPU)\n!pip install faster-whisper\n\n\nprint(\"‚úÖ ƒê√£ c√†i ƒë·∫∑t xong v√† t·∫£i video m·∫´u th√†nh c√¥ng!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T18:34:32.448848Z","iopub.execute_input":"2025-11-30T18:34:32.449614Z","iopub.status.idle":"2025-11-30T18:34:35.759148Z","shell.execute_reply.started":"2025-11-30T18:34:32.449585Z","shell.execute_reply":"2025-11-30T18:34:35.758189Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: faster-whisper in /usr/local/lib/python3.11/dist-packages (1.2.1)\nRequirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (4.6.1)\nRequirement already satisfied: huggingface-hub>=0.21 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (0.36.0)\nRequirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (0.21.2)\nRequirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (1.23.2)\nRequirement already satisfied: av>=11 in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (16.0.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from faster-whisper) (4.67.1)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (75.2.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (1.26.4)\nRequirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (6.0.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21->faster-whisper) (3.20.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21->faster-whisper) (2025.10.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21->faster-whisper) (25.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21->faster-whisper) (2.32.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21->faster-whisper) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21->faster-whisper) (1.2.0)\nRequirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (15.0.1)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (25.2.10)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (4.25.3)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->ctranslate2<5,>=4.0->faster-whisper) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->ctranslate2<5,>=4.0->faster-whisper) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->ctranslate2<5,>=4.0->faster-whisper) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->ctranslate2<5,>=4.0->faster-whisper) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->ctranslate2<5,>=4.0->faster-whisper) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->ctranslate2<5,>=4.0->faster-whisper) (2.4.1)\nRequirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper) (10.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21->faster-whisper) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21->faster-whisper) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21->faster-whisper) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21->faster-whisper) (2025.10.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->ctranslate2<5,>=4.0->faster-whisper) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->ctranslate2<5,>=4.0->faster-whisper) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->ctranslate2<5,>=4.0->faster-whisper) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->ctranslate2<5,>=4.0->faster-whisper) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->ctranslate2<5,>=4.0->faster-whisper) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->ctranslate2<5,>=4.0->faster-whisper) (2024.2.0)\n‚úÖ ƒê√£ c√†i ƒë·∫∑t xong v√† t·∫£i video m·∫´u th√†nh c√¥ng!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## Code x·ª≠ l√Ω (Core Logic)","metadata":{}},{"cell_type":"code","source":"import time\nfrom faster_whisper import WhisperModel\n\n# --- C·∫§U H√åNH ---\nvideo_path = \"/kaggle/input/example-vod/34378351509-1-192.mp4\" # ƒê∆∞·ªùng d·∫´n video (thay b·∫±ng file c·ªßa b·∫°n sau n√†y)\noutput_file = \"/kaggle/working/ex.txt\"\nmodel_size = \"large-v3\"         # M√¥ h√¨nh x·ªãn nh·∫•t\n# model_size = \"medium\"         # D√πng c√°i n√†y n·∫øu mu·ªën test nhanh h∆°n n·ªØa\n\nprint(f\"üöÄ ƒêang load m√¥ h√¨nh {model_size} v√†o GPU T4...\")\n# device=\"cuda\" -> B·∫Øt bu·ªôc ƒë·ªÉ d√πng GPU\n# compute_type=\"float16\" -> T·∫≠n d·ª•ng s·ª©c m·∫°nh t√≠nh to√°n c·ªßa T4\nmodel = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\n\nprint(\"‚è≥ ƒêang b·∫Øt ƒë·∫ßu x·ª≠ l√Ω video (Transcribing)...\")\nstart_time = time.time()\n\n# --- X·ª¨ L√ù ---\n# beam_size=5: Gi√∫p AI d√≤ t√¨m c√¢u ch√≠nh x√°c h∆°n\nsegments, info = model.transcribe(\n    video_path, \n    beam_size=5,\n    vad_filter=True,\n    vad_parameters=dict(min_silence_duration_ms=500)\n)\n\n# --- HI·ªÇN TH·ªä K·∫æT QU·∫¢ ---\nprint(f\"\\nDetected language: {info.language} (ƒê·ªô tin c·∫≠y: {info.language_probability:.2f})\")\nprint(\"-\" * 50)\nprint(f\"{'TIME START':<10} | {'TIME END':<10} | {'TEXT CONTENT'}\")\nprint(\"-\" * 50)\n\nfull_text_log = \"\"\nprint(video_path)\n# segments l√† m·ªôt generator (n√≥ ch·∫°y ƒë·∫øn ƒë√¢u nh·∫£ ch·ªØ ƒë·∫øn ƒë√≥)\nwith open(output_file, \"w\", encoding=\"utf-8\") as f:\n    for segment in segments:\n        # ƒê·ªãnh d·∫°ng th·ªùi gian cho ƒë·∫πp\n        start = f\"{segment.start:.2f}s\"\n        end = f\"{segment.end:.2f}s\"\n        text = segment.text\n        \n        # In ra m√†n h√¨nh d·∫°ng b·∫£ng\n        print(start)\n        f.write(start + \"\\n\")\n        print(end)\n        f.write(end + \"\\n\")\n        print(text)\n        f.write(text + \"\\n\")\n        \n    \n        # L∆∞u l·∫°i text ƒë·ªÉ d√πng cho vi·ªác kh√°c (nh∆∞ D·ªãch thu·∫≠t)\n        full_text_log += text + \" \"\n\nend_time = time.time()\nprint(\"-\" * 50)\nprint(f\"‚úÖ X·ª≠ l√Ω xong trong: {end_time - start_time:.2f} gi√¢y\")\nprint(\"\\nüìù TO√ÄN B·ªò VƒÇN B·∫¢N G·ªòP:\")\nprint(full_text_log.strip())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T18:34:35.761073Z","iopub.execute_input":"2025-11-30T18:34:35.761304Z","iopub.status.idle":"2025-11-30T18:34:37.630129Z","shell.execute_reply.started":"2025-11-30T18:34:35.761281Z","shell.execute_reply":"2025-11-30T18:34:37.629028Z"}},"outputs":[{"name":"stdout","text":"üöÄ ƒêang load m√¥ h√¨nh large-v3 v√†o GPU T4...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/807399446.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# device=\"cuda\" -> B·∫Øt bu·ªôc ƒë·ªÉ d√πng GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# compute_type=\"float16\" -> T·∫≠n d·ª•ng s·ª©c m·∫°nh t√≠nh to√°n c·ªßa T4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWhisperModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"float16\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚è≥ ƒêang b·∫Øt ƒë·∫ßu x·ª≠ l√Ω video (Transcribing)...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/faster_whisper/transcribe.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_size_or_path, device, device_index, compute_type, cpu_threads, num_workers, download_root, local_files_only, files, revision, use_auth_token, **model_kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m             )\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m         self.model = ctranslate2.models.Whisper(\n\u001b[0m\u001b[1;32m    690\u001b[0m             \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA failed with error out of memory"],"ename":"RuntimeError","evalue":"CUDA failed with error out of memory","output_type":"error"}],"execution_count":9},{"cell_type":"markdown","source":"# Translate","metadata":{}},{"cell_type":"code","source":"# C√†i ƒë·∫∑t phi√™n b·∫£n protobuf \"h√≤a b√¨nh\" nh·∫•t cho c·∫£ TensorFlow v√† Transformers\n!pip install protobuf==4.25.3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T18:34:37.630602Z","iopub.status.idle":"2025-11-30T18:34:37.630821Z","shell.execute_reply.started":"2025-11-30T18:34:37.630714Z","shell.execute_reply":"2025-11-30T18:34:37.630723Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from faster_whisper import WhisperModel\nfrom transformers import pipeline\nimport torch\n\n# --- B∆Ø·ªöC 1: KH·ªûI T·∫†O C√ÅC M√î H√åNH ---\n\n# 1.1 Load Whisper (ƒê·ªÉ nghe ti·∫øng Trung)\nprint(\"üöÄ ƒêang load Whisper Large-v3...\")\nwhisper_model = WhisperModel(\"large-v3\", device=\"cuda\", compute_type=\"float16\")\n\n# 1.2 Load NLLB (ƒê·ªÉ d·ªãch Trung -> Vi·ªát)\n# zho_Hans = Ti·∫øng Trung Gi·∫£n Th·ªÉ (Ph·ªï bi·∫øn nh·∫•t)\n# vie_Latn = Ti·∫øng Vi·ªát\nprint(\"üöÄ ƒêang load NLLB Translator...\")\ntranslator = pipeline(\n    'translation', \n    model=\"facebook/nllb-200-distilled-1.3B\", \n    device=0, # Ch·∫°y tr√™n GPU\n    src_lang=\"zho_Hans\", \n    tgt_lang=\"vie_Latn\"\n)\n\n# --- B∆Ø·ªöC 2: X·ª¨ L√ù VIDEO ---\n\nvideo_path = \"/kaggle/input/example-vod/34378351509-1-192.mp4\" \n\nprint(\"\\nüéß ƒêang t√°ch l·ªùi ti·∫øng Trung...\")\n# task=\"transcribe\": Y√™u c·∫ßu n√≥ ch√©p ƒë√∫ng ti·∫øng g·ªëc (Trung), ƒë·ª´ng c·ªë d·ªãch sang Anh\nsegments, info = whisper_model.transcribe(\n    video_path, \n    beam_size=5, \n    language=\"zh\",     # √âp nh·∫≠n di·ªán ti·∫øng Trung\n    task=\"transcribe\", # Ch·ªâ ch√©p l·∫°i, kh√¥ng d·ªãch v·ªôi\n    vad_filter=True\n)\n\nprint(f\"‚úÖ ƒê√£ nh·∫≠n di·ªán ng√¥n ng·ªØ: {info.language}\")\nprint(\"=\"*60)\nprint(f\"{'TH·ªúI GIAN':<15} | {'TI·∫æNG TRUNG (G·ªêC)':<30} | {'TI·∫æNG VI·ªÜT (D·ªäCH)'}\")\nprint(\"=\"*60)\n\n# --- B∆Ø·ªöC 3: V·ª™A CH·∫†Y V·ª™A D·ªäCH ---\noutput_file = \"phu_de_viet.txt\"\n\nwith open(output_file, \"w\", encoding=\"utf-8\") as f:\n    for segment in segments:\n        text_trung = segment.text\n        \n        # ƒê∆∞a ti·∫øng Trung v√†o NLLB ƒë·ªÉ d·ªãch sang Vi·ªát\n        # max_length=512 ƒë·ªÉ tr√°nh l·ªói n·∫øu c√¢u qu√° d√†i\n        ket_qua_dich = translator(text_trung, max_length=512)\n        text_viet = ket_qua_dich[0]['translation_text']\n        \n        # In ra m√†n h√¨nh cho s∆∞·ªõng m·∫Øt\n        time_stamp = f\"{segment.start:.2f}s -> {segment.end:.2f}s\"\n        print(f\"{time_stamp:<15} | {text_trung[:30]:<30}... | {text_viet}\")\n        \n        # Ghi v√†o file (ch·ªâ ghi ti·∫øng Vi·ªát ho·∫∑c c·∫£ hai t√πy b·∫°n)\n        # ·ªû ƒë√¢y m√¨nh ghi d·∫°ng: [Th·ªùi gian] Ti·∫øng Vi·ªát\n        f.write(f\"[{time_stamp}] {text_viet}\\n\")\n        \n\nprint(f\"\\n‚úÖ Xong! ƒê√£ l∆∞u ph·ª• ƒë·ªÅ ti·∫øng Vi·ªát v√†o file: {output_file}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T18:34:37.632386Z","iopub.status.idle":"2025-11-30T18:34:37.632735Z","shell.execute_reply.started":"2025-11-30T18:34:37.632539Z","shell.execute_reply":"2025-11-30T18:34:37.632554Z"}},"outputs":[],"execution_count":null}]}